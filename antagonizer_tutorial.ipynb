{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc28835a-4b8e-49fb-b34a-6caa2ebfea6f",
   "metadata": {},
   "source": [
    "## ANTAGONIZER\n",
    "\n",
    "Map polarity/partisanship between two categories of authors, based on a manually provided list of classifying words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236c959-4500-4efd-9b4c-31ca2cf57b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import antagonizer as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b0735-7aec-4ada-8245-7f0f31aed148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('climate_data.csv') # file not provided with the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3b84a-7647-4194-b76c-213e5a3ba5a4",
   "metadata": {},
   "source": [
    "----\n",
    "#### `.prepare_data(df, threshold)`\n",
    "Read a pandas dataframe including the columns `author` and `text`. Keep authors with a number of documents that is `> threshold`.\n",
    "\n",
    "Merge docs into docs-per-user. Preprocess and add bigrams.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f359db-a594-448e-aa8b-2708df34d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = az.prepare_data(dataset, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1045d8-1d4b-4489-bda4-bdea8a2ed94a",
   "metadata": {},
   "source": [
    "----\n",
    "#### `.categorize(prep_df,cat1,cat2,cat3,tags1,tags2)`\n",
    "Read the prepared dataframe. Categorize it into two named categories, as well as a hybrid category, based on the use of words in two manually defined lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf9f98-e313-4cbc-8eda-8f161e579ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following are examples\n",
    "cat1 = 'denialism'\n",
    "cat2 = 'activism'\n",
    "cat3 = 'hybrid'\n",
    "tags1 = ['hoax', 'leftist']\n",
    "tags2 = ['fridaysforfuture', 'denial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa6d5d-6d24-4581-a2df-1c57eb5ecdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = az.categorize(prep_df,cat1,cat2,cat3,tags1,tags2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebfabf-38d7-49f1-9a32-a6f3fbb092a6",
   "metadata": {},
   "source": [
    "----\n",
    "#### `.partisan_phrases(prep_df,max_df,min_df,cat1,cat2)`\n",
    "\n",
    "Calculate a bias_score for phrases, reflecting partisanship of language-use. The method used draws on a workflow described [here](https://towardsdatascience.com/detecting-politically-biased-phrases-from-u-s-senators-with-natural-language-processing-tutorial-d6273211d331). The maths for calculating bias is based on the paper _Auditing the partisanship of Google search snippets_ ([Hu et al. , 2019](https://dl.acm.org/doi/10.1145/3308558.3313654)).\n",
    "\n",
    "The `max_df` and `min_df` parameters speak with the corresponding parameters in [sklearn's CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f81fc7-6e91-416d-b43e-10792d7b7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_df = az.partisan_phrases(cat_df,max_df=0.8,min_df=10,cat1=cat1,cat2=cat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623680d0-5fe4-4f1a-9435-d72b4976ed32",
   "metadata": {},
   "source": [
    "----\n",
    "#### `.score_authors(phrases_df,cat_df)`\n",
    "Phrases in `phrases_df` have a bias score between -1 (category 1 partisan) and 1 (category 2 partisan). This function will score authors (mean bias score) based on their use of phrases.\n",
    "\n",
    "We want to use the most polarising phrases to score authors. We set a `polarity_cutoff`, where e.g. `0.6` means including phrases with a score below `-0,6` and above `0.6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f7313-94f9-44df-a805-04a18f0c8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "inal_df = az.score_authors(phrases_df,cat_df,polarity_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32b0e8-08df-4252-8493-f2e377117d89",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "#### `.reduce(final_df,cat1,cat2,cat3)`\n",
    "Reduce the dataframe by removing less active authors, to make plotting less demanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067e5b3-66cc-4202-9b3b-67d845314f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = az.reduce(final_df,cat1,cat2,cat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac6370-9891-43b7-8d7f-da3a153be900",
   "metadata": {},
   "source": [
    "----\n",
    "#### `.plot(plot_df,plotcut,colour1,colour2,colour3,width,height)`\n",
    "\n",
    "Plot the data using [Bokeh](https://bokeh.org/). The `plotcut` parameter decides how many items should be drawn on the plot (start with lower and increase).\n",
    "\n",
    "To set other parameters than the colours, width, and height, edit the source of the `plot()` function.\n",
    "\n",
    "This draws an interactive plot, for inspection, and where mouse hover labels reveal author data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a45e62-2ced-4639-acc9-4d43332c5ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = az.plot(plot_df,4000, 'purple','green','grey',800,550)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6bccd7-a9f3-4e4d-b354-45ccb342e9de",
   "metadata": {},
   "source": [
    "----\n",
    "#### Deluxe plot\n",
    "Plot the full `final_df` using [Seaborn](https://seaborn.pydata.org/). This method draws a scatterplot, with kde density contours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd974f-3c1c-4478-8846-4bcf5b49e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final_df = pd.read_csv('final_df.csv')\n",
    "\n",
    "sns.set(rc={'axes.facecolor':'lightgrey', 'figure.facecolor':'white', \n",
    "            'legend.markerscale':1.4, 'font.family' : \"monospace\"})\n",
    "x = final_df.authorscores\n",
    "y = final_df.numdocs\n",
    "category = final_df.category\n",
    "\n",
    "# Draw a combo histogram and scatterplot with density contours\n",
    "f, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.set(yscale=\"log\", xlabel = 'Polarity', ylabel='Log number of documents', yticks= [500,1000,8000], yticklabels = ['500','1000','8000'], xlim = (-1,1))\n",
    "\n",
    "scatter = sns.scatterplot(x=x, y=y, s=80, color=\".15\", data= final_df, alpha=0.6, hue=category, palette=dict(hybrid=\"darkgrey\", denialism=\"purple\", activism=\"green\"), linewidth=0)\n",
    "density = sns.kdeplot(x=x, y=y, levels=50, color=\"black\", linewidths=0.6, alpha = 0.8)\n",
    "\n",
    "scatter.legend(fontsize = 15, \\\n",
    "               bbox_to_anchor= (1.05, 1), \\\n",
    "               loc=2,\n",
    "               borderaxespad=0,\n",
    "               title= \"Discursive orientation\", \\\n",
    "               title_fontsize = 16, \\\n",
    "               facecolor = 'white',\n",
    "               edgecolor = 'white'\n",
    "              )\n",
    "plt.savefig('full_plot.png')\n",
    "plt.savefig('full_plot.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
